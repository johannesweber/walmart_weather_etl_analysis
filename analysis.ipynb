{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import statsmodels.api as sm\n",
    "from config import constants\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper.helper import Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable division by zero warning\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# disabling max open windows warning in matplotlib\n",
    "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# deactivate SettingWithCopyWarning:\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(constants.SOURCE_FILE, sheet_name=constants.XLSX_SHEET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null ids\n",
    "df.dropna(subset=['store_nbr', 'station_nbr', 'item_nbr'], inplace=True)\n",
    "# delete lines where units greather than 0\n",
    "df = df[df['units'] > 0]\n",
    "# create new df with only relevant columns\n",
    "relevant_columns = ['date', 'item_nbr', 'station_nbr', 'store_nbr', 'units', 'tmin', 'tmax', 'tavg', 'wetbulb', 'dewpoint', 'snowfall', 'preciptotal', 'avgspeed']\n",
    "df_new = df[relevant_columns]\n",
    "# calculate humidity\n",
    "df_new['humidity'] = df_new.apply(func=Helper.calculate_relative_humidity_jupyter, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Store and Item IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = df_new['store_nbr'].unique()\n",
    "items = df_new['item_nbr'].unique()\n",
    "dates = df_new['date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect significant Attributes with Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all rows from item per store\n",
    "significant_columns = []\n",
    "\n",
    "for store_id in stores:\n",
    "    for item_id in items:\n",
    "        df_reg = df_new[(df_new['store_nbr'] == store_id) & (df_new['item_nbr'] == item_id)]\n",
    "        if df_reg.shape[0] > 0:\n",
    "            df_reg.fillna(0, inplace=True)\n",
    "            feature_columns = ['snowfall', 'preciptotal', 'tavg', 'tmin', 'tmax', 'humidity', 'avgspeed']\n",
    "            x = df_reg[feature_columns]\n",
    "            y = df_reg[['units']]\n",
    "            # x = sm.add_constant(x)\n",
    "            model = sm.OLS(y, x).fit()\n",
    "            p_values = model.pvalues\n",
    "            for column in feature_columns:\n",
    "                p_value = float(p_values[column])\n",
    "                if (not np.isnan(p_value)) and (p_value < constants.SIGNIFICANT_LIMIT):\n",
    "                    summary = (store_id, item_id, column, p_value, model)\n",
    "                    significant_columns.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking R2 Adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for summary_tuple in significant_columns:\n",
    "    column_model = summary_tuple[4]\n",
    "    column_name = summary_tuple[2]\n",
    "    print(column_model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for summary_tuple in significant_columns:\n",
    "    column_model = summary_tuple[4]\n",
    "    column_name = summary_tuple[2]\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    fig = sm.graphics.plot_regress_exog(column_model, column_name, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation instead of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_correlation = []\n",
    "\n",
    "for store_id in stores:\n",
    "    for item_id in items:\n",
    "        df_reg = df_new[(df_new['store_nbr'] == store_id) & (df_new['item_nbr'] == item_id)]\n",
    "        if df_reg.shape[0] > 0:\n",
    "            df_reg.fillna(0, inplace=True)\n",
    "            feature_columns = ['snowfall', 'preciptotal', 'tavg', 'tmin', 'tmax', 'humidity', 'avgspeed', 'units']\n",
    "            corr_df = df_reg[feature_columns]\n",
    "            corr = corr_df.corr(method='spearman')\n",
    "            for a in feature_columns:\n",
    "                for b in feature_columns:\n",
    "                    if (a == 'units') or (b == 'units'):\n",
    "                        correlation_value = corr[a][b]\n",
    "                        if (not np.isnan(correlation_value)) and (abs(correlation_value) > constants.HIGH_CORRELATION) and (abs(correlation_value) != 1):\n",
    "                            summary_tuple = (store_id, item_id, a, b, correlation_value, corr)\n",
    "                            high_correlation.append(summary_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting correlation with Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for correlation_tuple in high_correlation:\n",
    "    corr = correlation_tuple[5]\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    mappable = ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=60);\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns);\n",
    "    plt.colorbar(mappable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting correlation with Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for correlation_tuple in high_correlation:\n",
    "    store_id = correlation_tuple[0]\n",
    "    item_id = correlation_tuple[1]\n",
    "    column_a = correlation_tuple[2]\n",
    "    column_b = correlation_tuple[3]\n",
    "    corr_value = correlation_tuple[4]\n",
    "    print(store_id, item_id, column_a, column_b, corr_value)\n",
    "    df_corr = df_new[(df_new['store_nbr'] == store_id) & (df_new['item_nbr'] == item_id)]\n",
    "    if column_a == 'units':\n",
    "        x = df_corr[column_b]\n",
    "        y = df_corr[column_a]\n",
    "    else:\n",
    "        x = df_corr[column_a]\n",
    "        y = df_corr[column_b]\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting trends for significant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# fetching units per item/store\n",
    "            if trend_df.shape[0] > 0:\n",
    "                trend_df.fillna(0, inplace=True)\n",
    "                trend_df['date'] = trend_df['date'] + 1\n",
    "                trend_df.rename(index=str, columns={\"date\": \"day\"}, inplace=True)\n",
    "                trend_df.set_index('day', inplace=True)\n",
    "                trend_df.plot(figsize=(8, 5), linewidth=4, fontsize=12)\n",
    "                plt.xlabel('Day', fontsize=12)\n",
    "                y_label = 'Item ' + str(key) + ' in Store ' + str(store_id[0])\n",
    "                plt.ylabel(y_label, fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
